% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{regularized_pocket}
\alias{regularized_pocket}
\title{Perform regularized pocket algorithm}
\usage{
regularized_pocket(x, y, weight_elimination, weight_decay, maxit)
}
\arguments{
\item{x}{A numeric matrix with \eqn{n} rows. Should NOT include
a column of all 1s for bias weight.}

\item{y}{a numeric vector with \eqn{n} columns}

\item{weight_elimination}{\eqn{\eta} in the description}

\item{weight_decay}{\eqn{\lambda} in the description}

\item{maxit}{the maximum number of iteratoins}
}
\value{
perceptron weights
}
\description{
Performs the Perceptron Learning Algorithm with two regularization
constants.
}
\details{
\deqn{
    [[sign(w^Tx_n) \neq y_n]]
    + \frac{\eta}{2n}\sum_{i=1}^d\frac{w_i^2}{1+w_i^2}
    + \frac{\lambda}{2n} \sum_{i=1}^d w_i^2
}
We treat the PLA update as a ``derivative" of the first component.
So, our update in the \eqn{i}th component will be
\deqn{
    PLA_update
    - \frac{\eta}{n}\frac{w_i}{(1+w_i^2)^2}
    - \frac{\lambda}{n} w_i
}
}
